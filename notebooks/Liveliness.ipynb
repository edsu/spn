{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liveliness\n",
    "\n",
    "It would be useful to know what archived URLs are still available on the web, and which are not. Determining if something is still available on the web is surprisingly fraught, because some web servers respond to 200 OK instead of 404 Not Found for things that are no longer available. So it's possible that we will get false positives in these results (higher numbers of URLs that are alive). But that's ok because we'll get a generous measure of liveliness which means we won't over-\n",
    "\n",
    "We do have a lot of URLs, and it's probably easier for us if we sample again. It also would be useful to be able to sample by year. Lets start by getting our urls dataset into Spark again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=warc-analysis, master=local[*]) created by __init__ at ../utils/warc_spark.py:51 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-88909660fa54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarc_spark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/urls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/spn/utils/warc_spark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(memory)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetSystemProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.executor.memory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warc-analysis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0msqlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/opt/apache-spark/libexec/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=warc-analysis, master=local[*]) created by __init__ at ../utils/warc_spark.py:51 "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from warc_spark import init\n",
    "\n",
    "sc, sqlc = init()\n",
    "urls = sqlc.read.csv('results/urls', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = urls.filter(urls.date.startswith('2018-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our sample, with a confidence interval of 5% and a confidence level of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = year.count()\n",
    "sample_size = int(pop_size / (1 + pop_size * (.05**2)))\n",
    "sample_list = year.rdd.takeSample(withReplacement=False, num=sample_size, seed=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the sample into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warc_file</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>user_agent_family</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2&gt;</th>\n",
       "      <td>warcs/liveweb-20181025034513/live-201810250335...</td>\n",
       "      <td>2018-10-25T03:39:24Z</td>\n",
       "      <td>https://www.youtube.com/channel/UCgefQJC5UgbWJ...</td>\n",
       "      <td>Wget/1.19.5 (linux-gnu)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0&gt;</th>\n",
       "      <td>warcs/liveweb-20181025014552/live-201810250114...</td>\n",
       "      <td>2018-10-25T01:15:18Z</td>\n",
       "      <td>http://km.aifb.kit.edu/projects/numbers/web/n2...</td>\n",
       "      <td>Wget/1.19.4 (darwin17.3.0)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a&gt;</th>\n",
       "      <td>warcs/liveweb-20181025070807/live-201810250655...</td>\n",
       "      <td>2018-10-25T06:58:26Z</td>\n",
       "      <td>https://www.wykop.pl/wpis/36150773/mow-do-mnie...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:6...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077&gt;</th>\n",
       "      <td>warcs/liveweb-20181025070807/live-201810250647...</td>\n",
       "      <td>2018-10-25T07:13:52Z</td>\n",
       "      <td>https://www.instagram.com/mufmunkedal/</td>\n",
       "      <td>python-requests/2.19.1</td>\n",
       "      <td>Python Requests</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;urn:uuid:2d08611a-8639-4dcb-8891-445454493535&gt;</th>\n",
       "      <td>warcs/liveweb-20181025111513/live-201810251107...</td>\n",
       "      <td>2018-10-25T11:12:37Z</td>\n",
       "      <td>https://www.wykop.pl/wpis/36154923/wrocil-i-od...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:6...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         warc_file  \\\n",
       "record_id                                                                                            \n",
       "<urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2>  warcs/liveweb-20181025034513/live-201810250335...   \n",
       "<urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0>  warcs/liveweb-20181025014552/live-201810250114...   \n",
       "<urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a>  warcs/liveweb-20181025070807/live-201810250655...   \n",
       "<urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077>  warcs/liveweb-20181025070807/live-201810250647...   \n",
       "<urn:uuid:2d08611a-8639-4dcb-8891-445454493535>  warcs/liveweb-20181025111513/live-201810251107...   \n",
       "\n",
       "                                                                 date  \\\n",
       "record_id                                                               \n",
       "<urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2>  2018-10-25T03:39:24Z   \n",
       "<urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0>  2018-10-25T01:15:18Z   \n",
       "<urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a>  2018-10-25T06:58:26Z   \n",
       "<urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077>  2018-10-25T07:13:52Z   \n",
       "<urn:uuid:2d08611a-8639-4dcb-8891-445454493535>  2018-10-25T11:12:37Z   \n",
       "\n",
       "                                                                                               url  \\\n",
       "record_id                                                                                            \n",
       "<urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2>  https://www.youtube.com/channel/UCgefQJC5UgbWJ...   \n",
       "<urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0>  http://km.aifb.kit.edu/projects/numbers/web/n2...   \n",
       "<urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a>  https://www.wykop.pl/wpis/36150773/mow-do-mnie...   \n",
       "<urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077>             https://www.instagram.com/mufmunkedal/   \n",
       "<urn:uuid:2d08611a-8639-4dcb-8891-445454493535>  https://www.wykop.pl/wpis/36154923/wrocil-i-od...   \n",
       "\n",
       "                                                                                        user_agent  \\\n",
       "record_id                                                                                            \n",
       "<urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2>                            Wget/1.19.5 (linux-gnu)   \n",
       "<urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0>                         Wget/1.19.4 (darwin17.3.0)   \n",
       "<urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a>  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:6...   \n",
       "<urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077>                             python-requests/2.19.1   \n",
       "<urn:uuid:2d08611a-8639-4dcb-8891-445454493535>  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:6...   \n",
       "\n",
       "                                                user_agent_family    bot  \n",
       "record_id                                                                 \n",
       "<urn:uuid:584496d7-5296-4395-9362-7f7aba03ece2>              Wget   true  \n",
       "<urn:uuid:8c658003-6728-4cfa-a178-6d062fc0e5b0>              Wget   true  \n",
       "<urn:uuid:b4450919-a293-48c4-a163-31818f3ddb4a>           Firefox  false  \n",
       "<urn:uuid:4f5a9ec0-4056-4336-99c9-de811dadf077>   Python Requests   true  \n",
       "<urn:uuid:2d08611a-8639-4dcb-8891-445454493535>           Firefox  false  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.options.display.width = 0\n",
    "\n",
    "sample = pandas.DataFrame(sample_list, columns=year.schema.fieldNames())\n",
    "sample = sample.set_index('record_id')\n",
    "sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function that checks if a URL is still available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://nytimes.com True\n",
      "https://nytimes.com/no-way-forgetaboutit False\n",
      "https://this.is.not.a.host.name False\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def alive(url):\n",
    "    result = False\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        if resp.status_code == 200:\n",
    "            result = True\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "for url in ['https://nytimes.com', 'https://nytimes.com/no-way-forgetaboutit', 'https://this.is.not.a.host.name']:\n",
    "    print(url, alive(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add a new column to our data containing whether it is on the Internet now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['alive'] = sample.url.map(alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=399\n",
      "dead=19\n",
      "alive=380\n"
     ]
    }
   ],
   "source": [
    "print('n={}'.format(len(sample)))\n",
    "print('dead={}'.format(len(sample.query('alive == False'))))\n",
    "print('alive={}'.format(len(sample.query('alive == True'))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bundle it up in a function so we can run it for different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liveliness(y):\n",
    "    year = urls.filter(urls.date.startswith(str(y) + '-'))\n",
    "    pop_size = year.count()\n",
    "    sample_size = int(pop_size / (1 + pop_size * (.05**2)))\n",
    "    sample_list = year.rdd.takeSample(withReplacement=False, num=sample_size, seed=21)\n",
    "    sample = pandas.DataFrame(sample_list, columns=year.schema.fieldNames())\n",
    "    sample = sample.set_index('record_id')\n",
    "    sample['alive'] = sample.url.map(alive)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make sure it returns the same thing that we calculated previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018 = liveliness(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=399\n",
      "dead=21\n",
      "alive=378\n"
     ]
    }
   ],
   "source": [
    "def print_stats(df):\n",
    "    print('n={}'.format(len(df)))\n",
    "    print('dead={}'.format(len(df.query('alive == False'))))\n",
    "    print('alive={}'.format(len(df.query('alive == True'))))\n",
    "\n",
    "print_stats(df2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They match! So now we can easily generate some stats for all the years and graph it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = {'year': [], 'status': [], 'percent': []}\n",
    "for year in range(2013, 2019):\n",
    "    y_df = liveliness(year)\n",
    "    alive_pct = len(y_df.query('alive == True')) / len(y_df) * 100\n",
    "    dead_pct = 100 - alive_pct\n",
    "    \n",
    "    source['year'].append(str(year))\n",
    "    source['status'].append('alive')\n",
    "    source['percent'].append(alive_pct)\n",
    "    \n",
    "    source['year'].append(str(year))\n",
    "    source['status'].append('dead')\n",
    "    source['percent'].append(dead_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pandas.DataFrame.from_dict(source)\n",
    "source_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair\n",
    "altair.renderers.enable('notebook')\n",
    "\n",
    "chart = altair.Chart(source_df).mark_bar().encode(\n",
    "    altair.X('year'),\n",
    "    altair.Y('percent:%'),\n",
    "    altair.Color('status', scale=altair.Scale(scheme='tableau20'))\n",
    ")\n",
    "\n",
    "chart = chart.properties(title=\"Liveness by Year\", width=250)\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
