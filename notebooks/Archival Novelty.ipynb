{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archival Novelty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores whether requests to archive web resources were the first such request. Or rather, whether the request provided the Internet Archive with first knowledge of the web resource. Let's call this *archival novelty* which will be the percentage of SavePageNow requests which brought new knowledge of a URL to the Internet Archive. We are specifically going to look at *archival novelty* in terms of SavePageNow requests from automated and human agents.\n",
    "\n",
    "The Internet Archive's [CDX API](https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server) can tell us exactly when a given URL has been archived over time. But there are 7 million requests for HTML pages in our dataset. So what we will do is randomly sample the requests and check those against the CDX API.\n",
    "\n",
    "First we will read in the URLS csv data that we generated in the URLs notebook back into a Spark DataFrame. Remember this only SavePageNow requests that resulted in an HTML responses, so it doesn't include things like images, JavaScript or CSS that SavePageNow could request when proxying an actual browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from warc_spark import init, extractor\n",
    "\n",
    "sc, sqlc = init()\n",
    "df = sqlc.read.csv('results/urls', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Samples\n",
    "\n",
    "Lets look specifically at 2018. Since millions of SavePageNow requests were received, and it's not feasible to query the CDX API millions of times, we will generate a random sample. Since we know the size of the population (number of requests) we will use the [Yamane Method](http://www.research-system.siam.edu/images/independent/Consumer_acceptance_of_air_purifier_products_in_China/CHAPTER_3.pdf) to calculate the sample size needed for a confidence interval of 5% and a confidence level of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 399\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "year = df.filter(df.date.like('2018%'))\n",
    "pop_size = year.count()\n",
    "sample_size = int(pop_size / (1 + pop_size * (.05**2)))\n",
    "sample = year.rdd.takeSample(withReplacement=False, num=sample_size, seed=42)\n",
    "\n",
    "print(\"sample size:\", len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>warc_file</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>user_agent_family</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;urn:uuid:e70603a2-096a-4f82-b66d-7bc2bb5f286e&gt;</td>\n",
       "      <td>warcs/liveweb-20181025043139/live-201810250352...</td>\n",
       "      <td>2018-10-25T04:12:23Z</td>\n",
       "      <td>http://eestipaevaleht.se/</td>\n",
       "      <td>Python-urllib/2.7</td>\n",
       "      <td>Python-urllib</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;urn:uuid:8d3949bd-c7c4-45a1-b11f-90a0975de679&gt;</td>\n",
       "      <td>warcs/liveweb-20181025212424/live-201810252105...</td>\n",
       "      <td>2018-10-25T21:23:14Z</td>\n",
       "      <td>http://km.aifb.kit.edu/projects/numbers/web/n2...</td>\n",
       "      <td>Wget/1.19.4 (darwin17.3.0)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;urn:uuid:87c47520-05d9-47ac-b8b5-79408549caff&gt;</td>\n",
       "      <td>warcs/liveweb-20181025170957/live-201810251658...</td>\n",
       "      <td>2018-10-25T17:05:13Z</td>\n",
       "      <td>https://socialblade.com/youtube/channel/UCCmXc...</td>\n",
       "      <td>Wget/1.19.5 (linux-gnu)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;urn:uuid:0b7d69ca-d38c-4d6c-9f91-bcb63c82265c&gt;</td>\n",
       "      <td>warcs/liveweb-20181025000937/cachegw-201810240...</td>\n",
       "      <td>2018-10-24T13:44:56Z</td>\n",
       "      <td>https://www.reg.ru/domain/shop/lot/rockderzhav...</td>\n",
       "      <td>Mozilla/5.0 (compatible; archive.org_bot; Wayb...</td>\n",
       "      <td>archive.org_bot</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;urn:uuid:572b5006-3a51-43df-94fc-95ccfea727af&gt;</td>\n",
       "      <td>warcs/liveweb-20181025165702/live-201810251631...</td>\n",
       "      <td>2018-10-25T16:47:20Z</td>\n",
       "      <td>http://abelhas.pt/action/LastAccounts/LastSeen...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:63...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         record_id  \\\n",
       "0  <urn:uuid:e70603a2-096a-4f82-b66d-7bc2bb5f286e>   \n",
       "1  <urn:uuid:8d3949bd-c7c4-45a1-b11f-90a0975de679>   \n",
       "2  <urn:uuid:87c47520-05d9-47ac-b8b5-79408549caff>   \n",
       "3  <urn:uuid:0b7d69ca-d38c-4d6c-9f91-bcb63c82265c>   \n",
       "4  <urn:uuid:572b5006-3a51-43df-94fc-95ccfea727af>   \n",
       "\n",
       "                                           warc_file                  date  \\\n",
       "0  warcs/liveweb-20181025043139/live-201810250352...  2018-10-25T04:12:23Z   \n",
       "1  warcs/liveweb-20181025212424/live-201810252105...  2018-10-25T21:23:14Z   \n",
       "2  warcs/liveweb-20181025170957/live-201810251658...  2018-10-25T17:05:13Z   \n",
       "3  warcs/liveweb-20181025000937/cachegw-201810240...  2018-10-24T13:44:56Z   \n",
       "4  warcs/liveweb-20181025165702/live-201810251631...  2018-10-25T16:47:20Z   \n",
       "\n",
       "                                                 url  \\\n",
       "0                          http://eestipaevaleht.se/   \n",
       "1  http://km.aifb.kit.edu/projects/numbers/web/n2...   \n",
       "2  https://socialblade.com/youtube/channel/UCCmXc...   \n",
       "3  https://www.reg.ru/domain/shop/lot/rockderzhav...   \n",
       "4  http://abelhas.pt/action/LastAccounts/LastSeen...   \n",
       "\n",
       "                                          user_agent user_agent_family    bot  \n",
       "0                                  Python-urllib/2.7     Python-urllib   true  \n",
       "1                         Wget/1.19.4 (darwin17.3.0)              Wget   true  \n",
       "2                            Wget/1.19.5 (linux-gnu)              Wget   true  \n",
       "3  Mozilla/5.0 (compatible; archive.org_bot; Wayb...   archive.org_bot   true  \n",
       "4  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:63...           Firefox  false  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pandas.DataFrame(sample, columns=year.schema.fieldNames())\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Novelty\n",
    "\n",
    "Now let's create a function that will return all the times a URL was archived. If supplied the `to` parameter will limit the results to snapshots that were taken prior to (and including) that time. This will limit the results we need to collect since we don't really need to know how many times a URL was collected *after* the time in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mith.umd.edu [20000815201749, 20001204145800, 20010201091600, 20010203124200, 20010224212144, 20010301092808, 20010302112313, 20010309133144, 20010404212235, 20010418164605, 20010515215143, 20010721201430, 20010924024921, 20011202065537, 20020601134123, 20020604040017, 20020802093507, 20020927173901, 20020929183602]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def archive_times(url, to=None):\n",
    "    params = {\"output\": \"json\", \"url\": url, \"limit\": 10000, 'showResumeKey': True}\n",
    "    if to:\n",
    "        params['to'] = to\n",
    "    \n",
    "    while True:\n",
    "        resp = requests.get('http://web.archive.org/cdx/search/cdx', params=params)\n",
    "        \n",
    "        if resp.status_code == 403:\n",
    "            # catch \"Blocked Site Error\" when robots.txt prevents lookup?\n",
    "            # e.g. http://www.jeuxvideo.com/forums/42-51-53683620-1-0-1-0-pour-etre-assure-au-niveau-de-la-sante-aux-usa.htm \n",
    "            yield None\n",
    "            break\n",
    "            \n",
    "        results = resp.json()\n",
    "        # ignore header\n",
    "        for result in results[1:]:\n",
    "            if len(result) > 1:\n",
    "                yield int(result[1])\n",
    "        \n",
    "        if len(results) != 0 and len(results[-1]) == 1:\n",
    "            params['resumeKey'] = results[-1][0]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "print('https://mith.umd.edu', list(archive_times('https://mith.umd.edu/', to=20020929183602)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that returns all the times that a URL was archived we can create another function `new_url` that takes a uRL and a date and determines whether the snapshot taken at that time was the first time the URL was seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def new_url(url, date):\n",
    "    # convert 2018-10-25T21:47:18Z to 20181025214718\n",
    "    request_date = int(re.sub(r'[:TZ-]', '', date))\n",
    "    \n",
    "    # cdx results should be sorted, but we'll make sure\n",
    "    times = sorted(archive_times(url, to=request_date))\n",
    "    if len(times) > 0:\n",
    "        return request_date == times[0]\n",
    "    else:\n",
    "        # sometimes it seems Wayback CDX doesn't know about things in the WARCs?\n",
    "        # e.g. http://josephinedark.net/code.php?PHPSESSID=96bb60faa7f178b21b949e9359129459\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out on the first ten rows in the humans sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://eestipaevaleht.se/ False\n",
      "http://km.aifb.kit.edu/projects/numbers/web/n2481513 True\n",
      "https://socialblade.com/youtube/channel/UCCmXcYtA4T9wxc3vmbGFxRA False\n",
      "https://www.reg.ru/domain/shop/lot/rockderzhava.ru?rid=2014 False\n",
      "http://abelhas.pt/action/LastAccounts/LastSeenRotation?TimeStamp=1540485933469&itemsCount=84&inRow=7&pageSize=21&page=4 True\n"
     ]
    }
   ],
   "source": [
    "for i, row in sample.head(5).iterrows():\n",
    "    print(row.url, new_url(row.url, row.date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go over to [Internet Archive's Wayback Machine](https://web.archive.org) to confirm the results. Now we can create our new column named `new_url` to indicate whether the URL was new when it was added to the Internet Archive. Depending on the number of rows in the sample this can take some time, since each row triggers a CDX API lookup, which will take about a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['new_url'] = pandas.Series(\n",
    "    [new_url(r.url, r.date) for i, r in sample.iterrows()], \n",
    "    index=sample.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>warc_file</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>user_agent_family</th>\n",
       "      <th>bot</th>\n",
       "      <th>new_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;urn:uuid:e70603a2-096a-4f82-b66d-7bc2bb5f286e&gt;</td>\n",
       "      <td>warcs/liveweb-20181025043139/live-201810250352...</td>\n",
       "      <td>2018-10-25T04:12:23Z</td>\n",
       "      <td>http://eestipaevaleht.se/</td>\n",
       "      <td>Python-urllib/2.7</td>\n",
       "      <td>Python-urllib</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;urn:uuid:8d3949bd-c7c4-45a1-b11f-90a0975de679&gt;</td>\n",
       "      <td>warcs/liveweb-20181025212424/live-201810252105...</td>\n",
       "      <td>2018-10-25T21:23:14Z</td>\n",
       "      <td>http://km.aifb.kit.edu/projects/numbers/web/n2...</td>\n",
       "      <td>Wget/1.19.4 (darwin17.3.0)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;urn:uuid:87c47520-05d9-47ac-b8b5-79408549caff&gt;</td>\n",
       "      <td>warcs/liveweb-20181025170957/live-201810251658...</td>\n",
       "      <td>2018-10-25T17:05:13Z</td>\n",
       "      <td>https://socialblade.com/youtube/channel/UCCmXc...</td>\n",
       "      <td>Wget/1.19.5 (linux-gnu)</td>\n",
       "      <td>Wget</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;urn:uuid:0b7d69ca-d38c-4d6c-9f91-bcb63c82265c&gt;</td>\n",
       "      <td>warcs/liveweb-20181025000937/cachegw-201810240...</td>\n",
       "      <td>2018-10-24T13:44:56Z</td>\n",
       "      <td>https://www.reg.ru/domain/shop/lot/rockderzhav...</td>\n",
       "      <td>Mozilla/5.0 (compatible; archive.org_bot; Wayb...</td>\n",
       "      <td>archive.org_bot</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;urn:uuid:572b5006-3a51-43df-94fc-95ccfea727af&gt;</td>\n",
       "      <td>warcs/liveweb-20181025165702/live-201810251631...</td>\n",
       "      <td>2018-10-25T16:47:20Z</td>\n",
       "      <td>http://abelhas.pt/action/LastAccounts/LastSeen...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:63...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         record_id  \\\n",
       "0  <urn:uuid:e70603a2-096a-4f82-b66d-7bc2bb5f286e>   \n",
       "1  <urn:uuid:8d3949bd-c7c4-45a1-b11f-90a0975de679>   \n",
       "2  <urn:uuid:87c47520-05d9-47ac-b8b5-79408549caff>   \n",
       "3  <urn:uuid:0b7d69ca-d38c-4d6c-9f91-bcb63c82265c>   \n",
       "4  <urn:uuid:572b5006-3a51-43df-94fc-95ccfea727af>   \n",
       "\n",
       "                                           warc_file                  date  \\\n",
       "0  warcs/liveweb-20181025043139/live-201810250352...  2018-10-25T04:12:23Z   \n",
       "1  warcs/liveweb-20181025212424/live-201810252105...  2018-10-25T21:23:14Z   \n",
       "2  warcs/liveweb-20181025170957/live-201810251658...  2018-10-25T17:05:13Z   \n",
       "3  warcs/liveweb-20181025000937/cachegw-201810240...  2018-10-24T13:44:56Z   \n",
       "4  warcs/liveweb-20181025165702/live-201810251631...  2018-10-25T16:47:20Z   \n",
       "\n",
       "                                                 url  \\\n",
       "0                          http://eestipaevaleht.se/   \n",
       "1  http://km.aifb.kit.edu/projects/numbers/web/n2...   \n",
       "2  https://socialblade.com/youtube/channel/UCCmXc...   \n",
       "3  https://www.reg.ru/domain/shop/lot/rockderzhav...   \n",
       "4  http://abelhas.pt/action/LastAccounts/LastSeen...   \n",
       "\n",
       "                                          user_agent user_agent_family    bot  \\\n",
       "0                                  Python-urllib/2.7     Python-urllib   true   \n",
       "1                         Wget/1.19.4 (darwin17.3.0)              Wget   true   \n",
       "2                            Wget/1.19.5 (linux-gnu)              Wget   true   \n",
       "3  Mozilla/5.0 (compatible; archive.org_bot; Wayb...   archive.org_bot   true   \n",
       "4  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:63...           Firefox  false   \n",
       "\n",
       "   new_url  \n",
       "0    False  \n",
       "1     True  \n",
       "2    False  \n",
       "3    False  \n",
       "4     True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calcuate the novelty for 2018, or the probability that a SavePageNow request generated brought a new URL to the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37343358395989973\n"
     ]
    }
   ],
   "source": [
    "novelty = len(sample.query('new_url == True')) / len(sample)\n",
    "print(novelty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can say: On October 25, 2018 37% of SavePageNow requests added a new (novel) URL to the archive. The margin of sampling error is 5% with 95% level of confidence.\n",
    "\n",
    "Let's save our sampled dataset since it did take some time to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('results/novelty-sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archival Novelty\n",
    "\n",
    "Now that we've added the `new_url` column we can calculate the *archival novelty* for each sample as the percentage of SavePageNow requests that brought brand new URLs to the Internet Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_novelty = len(bots_df.query(\"new_url == True\")) / len(bots_df) * 100\n",
    "print(\"bots: %{0:.2f}\".format(bots_novelty))\n",
    "\n",
    "humans_novelty = len(humans_df.query('new_url == True')) / len(humans_df) * 100\n",
    "print(\"humans: %{0:.2f}\".format(humans_novelty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_df.to_csv('results/bots-sample.csv')\n",
    "humans_df.to_csv('results/humans-sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would now be interesting to look at the percentages by year for all our years and visualize them as a barchart. To collect the data by year we'll create a function that bundles up all the operations we just did so we can call it for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novelty(year, bots):\n",
    "    pop = df.filter(df.date.like(year + '%')).filter(df.bot == bots)\n",
    "    pop_count = pop.count()\n",
    "    \n",
    "    if pop_count == 0:\n",
    "        return 0.0, 0, 0\n",
    "    \n",
    "    # determine n: \n",
    "    \n",
    "    sample = pop.sample(0.0001)\n",
    "    sample_df = sample.toPandas()\n",
    "\n",
    "    sample_df['new_url'] = pandas.Series(\n",
    "        [new_url(r.url, r.date) for i, r in sample_df.iterrows()], \n",
    "        index=sample_df.index\n",
    "    )\n",
    "    \n",
    "    novelty = len(sample_df.query(\"new_url == True\")) / len(sample_df)\n",
    "    return novelty, len(sample_df), pop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelty_by_year = {'novelty': [], 'year': [], 'agent': [], 'p': [], 'n': []}\n",
    "\n",
    "for year in range(2013, 2019):\n",
    "    y = str(year)\n",
    "    for bots in [True, False]:\n",
    "        nov, n, p = novelty(y, bots=bots)\n",
    "        print(\"year={} novelty={} n={} p={}\".format(y, nov, n, p))\n",
    "        novelty_by_year['novelty'].append(nov)\n",
    "        novelty_by_year['year'].append(y)\n",
    "        novelty_by_year['agent'].append('bots' if bots else 'humans')   \n",
    "        novelty_by_year['p'].append(p)\n",
    "        novelty_by_year['n'].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair\n",
    "altair.renderers.enable('notebook')\n",
    "\n",
    "novelty_df = pandas.DataFrame(novelty_by_year)\n",
    "\n",
    "chart = altair.Chart(novelty_df).mark_bar().encode(\n",
    "    altair.X('bots:N', title=''),    \n",
    "    altair.Y('novelty:Q', axis=altair.Axis(format='%')),\n",
    "    altair.Color('bots:N'), #, title='Bots', scale=altair.Scale(scheme='tableau20'))\n",
    "    altair.Column('year:O', title=''),\n",
    ")\n",
    "\n",
    "chart = chart.properties(\n",
    "    width=50,\n",
    "    title='Archival Novelty by Year'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
