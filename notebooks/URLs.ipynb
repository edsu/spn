{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs in Wayback SPN Data\n",
    "\n",
    "In addition to looking at popular host names it also could be useful to identify popular URLs that people (or bots) archived on each day. Were there attempts to archive multiple things on the same day, and what can we possibly infer about the significance of these multiple attempts?\n",
    "\n",
    "The trouble is that when a browser interacts with SavePageNow via the [web form](https://web.archive.org) it receive the HTML for the requested webpage which has been rewritten to include some JavaScript. This JavaScript gets the browser to request any additional resources that are needed for rendering the page (JavaScript, images, CSS, etc) through SavePageNow as well. This means that a more high-fidelity recording is made, since all the resources for a web page are needed to make it human readable.\n",
    "\n",
    "Some of these URLs may be for things like jQuery a Content Deliver Network, or a CSS file. These aren't terribly interesting in terms of this analysis which is attempting to find duplicates in the originally requested page. One thing we can do is limit our analysis to HTML pages, or requests that come back 200 OK with a `Content-Type` HTTP header containing text/html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warc_spark import init, extractor\n",
    "\n",
    "sc, sqlc = init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the URLs it's important that we also retain the User-Agent that executed the request, since this tells us something about the person or agent who initiated SavePageNow. Unfortunately the User-Agent is in the WARC Request record, and the Content-Type of the response is in the WARC Response record. To complicate matters further SavePageNow may record a response using a *revist* record if the response is identical to a previously response. This can happen when a given URL is requested multiple times in specific time window. Luckily these three record types can be merged together using the WARC-Record-ID and the WARC-Concurrent-To WARC headers.\n",
    "\n",
    "The `get_urls` function takes a WARC Record and depending on whether it is a request, response or revisit will return a tuple containing the record id and a dictionary with either a \"ua\" or \"url\" key (depending on the type of record). These dictionaries will be merged in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "@extractor\n",
    "def get_urls(record):\n",
    "    \n",
    "    date = record.rec_headers.get_header('WARC-Date').split('T')[0]\n",
    "    \n",
    "    if record.rec_type == 'request':\n",
    "        id = record.rec_headers.get_header('WARC-Concurrent-To')\n",
    "        ua = record.http_headers.get('user-agent')\n",
    "        if id and ua:\n",
    "            yield (id, {\"ua\": ua, \"date\": date})\n",
    "            \n",
    "    elif record.rec_type in ['response', 'revisit'] and 'html' in record.http_headers.get('content-type', ''):\n",
    "        id = record.rec_headers.get_header('WARC-Record-ID')\n",
    "        url = record.rec_headers.get_header('WARC-Target-URI')\n",
    "        status_code = record.http_headers.get_statuscode()\n",
    "        \n",
    "        # not all 200 OK text/html responses are for requests for HTML \n",
    "        # for example some sites return 200 OK with some HTML when an image isn't found\n",
    "        # this big of logic will try to identify known image, css and javascript extensions\n",
    "        # to elmiminate them from consideration.\n",
    "        \n",
    "        uri = urlparse(url)        \n",
    "        is_dependency = re.match(r'.*\\.(gif|jpg|jpeg|js|png|css)$', uri.path)\n",
    "        if not is_dependency and status_code == '200' and id and url:\n",
    "            yield (id, {\"url\": url, \"date\": date})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can analyze our WARC data by selecting the WARC files we want to process and applying the `get_urls` function to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<urn:uuid:bcf103dc-ac2f-40ea-928b-9c3b5fec297f>',\n",
       "  {'url': 'https://www.youtube.com/channel/UC6JnEv4XTE7kAG3B6PCXvnw/about',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:bcf103dc-ac2f-40ea-928b-9c3b5fec297f>',\n",
       "  {'ua': 'Wget/1.19.5 (linux-gnu)', 'date': '2018-10-25'}),\n",
       " ('<urn:uuid:8ec7b844-9cd0-4a9f-b8cc-98a0afb1d146>',\n",
       "  {'url': 'http://servermobile.net/index.php?_kzm_s=30000&_kzm_u=http%3A%2F%2Frealtime.search.yahoo.co.jp%2Fsearch%3Ffr%3Drts_top%26p%3D%25E5%25B1%25B1%25E5%258F%25A3%25E7%259C%259F%25E7%2594%25B1%25E5%25AD%2590%26ei%3DUTF-8%26sv%3D1',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:8ec7b844-9cd0-4a9f-b8cc-98a0afb1d146>',\n",
       "  {'ua': 'Hatena Antenna/0.5 (http://a.hatena.ne.jp/help)',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:105b2f42-4ec1-43db-995a-ba74163649ec>',\n",
       "  {'url': 'https://www.youtube.com/channel/UC1UzKYEYgUlobzJm-tocZCQ',\n",
       "   'date': '2018-10-25'})]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "warc_files = glob('warcs/liveweb-2018*/*.warc.gz')\n",
    "warcs = sc.parallelize(warc_files)\n",
    "results = warcs.mapPartitions(get_urls)\n",
    "results.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use [combineByKey](http://abshinn.github.io/python/apache-spark/2014/10/11/using-combinebykey-in-apache-spark/) method to merge the dictinaries using the WARC-Record-ID as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<urn:uuid:346ee541-a0a6-484a-b117-54fe87710d57>',\n",
       "  {'url': 'https://www.youtube.com/channel/UC-J-KZfRV8c13fOCkhXdLiQ/about',\n",
       "   'date': '2018-10-25',\n",
       "   'ua': 'Wget/1.19.5 (linux-gnu)'}),\n",
       " ('<urn:uuid:caf7a37b-8e95-45a6-bab7-3d2b6dbd8923>',\n",
       "  {'ua': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.81 Safari/537.36',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:c12629e9-ee0d-4ea5-92de-db439eeb5051>',\n",
       "  {'ua': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:1aa1c607-5b43-4d2b-9804-c801f7287f15>',\n",
       "  {'ua': 'mediawords bot (http://cyber.law.harvard.edu)',\n",
       "   'date': '2018-10-25'}),\n",
       " ('<urn:uuid:6f43b0ec-bd4e-44ab-94ec-ba8dafbfa440>',\n",
       "  {'ua': 'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
       "   'date': '2018-10-25'})]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unpack(d1, d2):\n",
    "    d1.update(d2)\n",
    "    return d1\n",
    "\n",
    "# merge the dataset using the record-id\n",
    "dataset = results.combineByKey(\n",
    "    lambda d: d,\n",
    "    unpack,\n",
    "    unpack\n",
    ")\n",
    "\n",
    "dataset.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we're going to convert our dictionaries into tuples so we can easily create a DataFrame out of them for analysis. As we don this we are also going to add two new columns for the User-Agent Family and whether it is a known bot. Some JSON files that were developed as part of the UserAgents notebook can help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ua_families = json.load(open('../analysis/results/ua-families.json'))\n",
    "top_uas = json.load(open('../analysis/results/top-uas.json'))\n",
    "\n",
    "def unpack(r):\n",
    "    id = r[0]\n",
    "    url = r[1].get(\"url\", \"\")\n",
    "    ua = r[1].get(\"ua\", \"\")\n",
    "    date = r[1].get(\"date\", \"\")\n",
    "    ua_f = ua_families.get(ua, \"\")\n",
    "    bot = top_uas.get(ua_f, False)\n",
    "    return (id, date, url, ua, ua_f, bot)\n",
    "\n",
    "unpacked_dataset = dataset.map(unpack)\n",
    "\n",
    "# Convert to a Spark DataFrame\n",
    "df = unpacked_dataset.toDF([\"record_id\", \"date\", \"url\", \"user_agent\", \"user_agent_family\", \"bot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(record_id='<urn:uuid:346ee541-a0a6-484a-b117-54fe87710d57>', date='2018-10-25', url='https://www.youtube.com/channel/UC-J-KZfRV8c13fOCkhXdLiQ/about', user_agent='Wget/1.19.5 (linux-gnu)', user_agent_family='Wget', bot=True),\n",
       " Row(record_id='<urn:uuid:caf7a37b-8e95-45a6-bab7-3d2b6dbd8923>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.81 Safari/537.36', user_agent_family='Chrome', bot=False),\n",
       " Row(record_id='<urn:uuid:c12629e9-ee0d-4ea5-92de-db439eeb5051>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36', user_agent_family='Chrome', bot=False),\n",
       " Row(record_id='<urn:uuid:1aa1c607-5b43-4d2b-9804-c801f7287f15>', date='2018-10-25', url='', user_agent='mediawords bot (http://cyber.law.harvard.edu)', user_agent_family='mediawords bot', bot=False),\n",
       " Row(record_id='<urn:uuid:6f43b0ec-bd4e-44ab-94ec-ba8dafbfa440>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko', user_agent_family='IE', bot=False),\n",
       " Row(record_id='<urn:uuid:68c4923d-ef9f-448d-8882-6f523c113d3f>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; Microsoft; Lumia 535 Dual SIM)', user_agent_family='IE Mobile', bot=False),\n",
       " Row(record_id='<urn:uuid:d887bed1-2ef8-4f8f-9971-8fe00fba66e5>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36', user_agent_family='Chrome', bot=False),\n",
       " Row(record_id='<urn:uuid:c34767af-cfff-4876-89d7-fc99e21fd6c4>', date='2018-10-25', url='http://km.aifb.kit.edu/projects/numbers/web/n2322734', user_agent='Wget/1.19.4 (darwin17.3.0)', user_agent_family='Wget', bot=True),\n",
       " Row(record_id='<urn:uuid:8e4142fe-32fc-47c5-9b47-6423e785bc79>', date='2018-10-25', url='', user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 11_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15G77', user_agent_family='Mobile Safari UI/WKWebView', bot=False),\n",
       " Row(record_id='<urn:uuid:90acf505-9588-4be7-93bd-1194215c8ff0>', date='2018-10-25', url='https://www.youtube.com/channel/UCANLZYMidaCbLQFWXBC95Jg/videos?flow=list&sort=p&view=0', user_agent='Wget/1.19.5 (linux-gnu)', user_agent_family='Wget', bot=True)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's save off these results before we do any more processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('../analysis/results/urls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's count the URLs and see which ones have appeared more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "if os.path.isdir('url-counts'):\n",
    "    shutil.rmtree('url-counts')\n",
    "\n",
    "from pyspark.sql.functions import countDistinct, desc\n",
    "\n",
    "for year in range(2013, 2019):\n",
    "    date = \"{}-10-25\".format(year)\n",
    "    url_counts = df.filter(df.date == date)\n",
    "    # if there aren't any (can heppen in dev) then don't output\n",
    "    if url_counts.count() == 0:\n",
    "        continue\n",
    "    url_counts = url_counts.groupBy(\"url\").count().sort(desc('count'))\n",
    "    url_counts = url_counts.filter(url_counts[\"count\"] > 1)\n",
    "    url_counts = url_counts.coalesce(1)\n",
    "    url_counts.write.csv('url-counts/{}'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
